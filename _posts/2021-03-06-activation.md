
---
title: "[DL] Activation Functions"
date: 2021-03-06 10:000 -0400
author : 정여진
categories :
  - paper-review
  - deep-learning
tags :
  - activation-function
  - deep-learning
use_math : true
---


Today we will look at different activation functions, especially the family of ReLU (Rectified Linear Unit) activation function.

Overall, there are two types of activation functions :
> Linear and Non-linear activation functions

though non-linear functions are mostly used. The simplest of linear activation functions takes the form $ f(x) = x$.
