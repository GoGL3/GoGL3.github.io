---
title: "[DL] Activation Functions"
date: 2021-03-03 10:000 -0400
author : 정여진
use_math : true
categories:
 - deep-learning
 tags:
 - activation-function
 - deep-learning 
---

Today we will look at different activation functions, especially the family of ReLU (Rectified Linear Unit) activation function.

Overall, there are two types of activation functions :
> Linear and Non-linear activation functions

though non-linear functions are mostly used. The simplest of linear activation functions takes the form $ f(x) = x$.
